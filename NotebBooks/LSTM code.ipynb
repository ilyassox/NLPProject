{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b3d77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "695dd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "606c8ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8401 entries, 0 to 8400\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         1800 non-null   float64\n",
      " 1   Feed       8397 non-null   object \n",
      " 2   Sentiment  8401 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 197.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11c53c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8cbc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment']=df['Sentiment'].astype(str)\n",
    "df['Feed']=df['Feed'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "389b6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 681.3 kB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "904029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"Feed\"].tolist()\n",
    "sentiments = df[\"Sentiment\"].tolist()\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Train tokenizer\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Save tokenizer as JSON file\n",
    "with open(\"tokenizerV5.json\", \"w\") as f:\n",
    "    json.dump(tokenizer.to_json(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b42e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from csv\n",
    "\n",
    "# Extract the texts and labels\n",
    "texts = df['Feed'].values\n",
    "labels = df['Sentiment'].values\n",
    "\n",
    "# Initialize a tokenizer with a given number of words to keep\n",
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "\n",
    "# Fit the tokenizer on the texts\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convert the texts to sequences of integers using the tokenizer\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_len = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Save the tokenizer as JSON\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizerV6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e347b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(df['Feed'].values)\n",
    "X = tokenizer.texts_to_sequences(df['Feed'].values)\n",
    "X = pad_sequences(X, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb69895",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tokenizer' object has no attribute 'to_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27868\\675546324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'to_str'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8806b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['Sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecd39db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9769ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5635d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1285a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d59485c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.6927\n",
      "Epoch 1: val_loss improved from inf to 0.42915, saving model to model.h5\n",
      "168/168 [==============================] - 360s 2s/step - loss: 0.6322 - accuracy: 0.6927 - val_loss: 0.4292 - val_accuracy: 0.8132\n",
      "Epoch 2/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.8787\n",
      "Epoch 2: val_loss improved from 0.42915 to 0.29728, saving model to model.h5\n",
      "168/168 [==============================] - 373s 2s/step - loss: 0.2858 - accuracy: 0.8787 - val_loss: 0.2973 - val_accuracy: 0.8698\n",
      "Epoch 3/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9165\n",
      "Epoch 3: val_loss improved from 0.29728 to 0.27725, saving model to model.h5\n",
      "168/168 [==============================] - 351s 2s/step - loss: 0.1929 - accuracy: 0.9165 - val_loss: 0.2773 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9405\n",
      "Epoch 4: val_loss did not improve from 0.27725\n",
      "168/168 [==============================] - 357s 2s/step - loss: 0.1371 - accuracy: 0.9405 - val_loss: 0.2955 - val_accuracy: 0.8698\n",
      "Epoch 5/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9433\n",
      "Epoch 5: val_loss did not improve from 0.27725\n",
      "168/168 [==============================] - 358s 2s/step - loss: 0.1124 - accuracy: 0.9433 - val_loss: 0.3110 - val_accuracy: 0.8713\n",
      "Epoch 6/20\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9507\n",
      "Epoch 6: val_loss did not improve from 0.27725\n",
      "168/168 [==============================] - 342s 2s/step - loss: 0.0997 - accuracy: 0.9507 - val_loss: 0.3315 - val_accuracy: 0.8668\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a160067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.63%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913b132",
   "metadata": {},
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c23d71",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "46382fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8bf4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16016\\1399188578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'modeldarija.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('modeldarija.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50873f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       m3alem bourjilia w illi ma yefehmouch yelzmou ...\n",
       "1                                             Ya m3alllam\n",
       "2                           Ma7lek! Zin ou fannena 7loua.\n",
       "3                          hhhhh ya bliiiiiiiida ya Hanen\n",
       "4                                Nikraha w ma5yebha pffff\n",
       "                              ...                        \n",
       "8396    نوفل ما يجيب كان المنح وخوف ملا زبالة منال عما...\n",
       "8397    نسبة مشاهدة كبيرة رغم التشويش الى صار ...برافو...\n",
       "8398                                 Mala ta7ana makyebha\n",
       "8399                                                Tefah\n",
       "8400                         walah ka3ba le mamstk pfffff\n",
       "Name: Feed, Length: 8401, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Feed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66865f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "text = \"maalem wlh\"\n",
    "text_sequence = tokenizer.texts_to_sequences([text])\n",
    "text_sequence_padded = pad_sequences(text_sequence, maxlen=250)\n",
    "prediction = model.predict(text_sequence_padded)[0]\n",
    "predicted_label = np.argmax(prediction)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569fd638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_6904\\192509584.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Feed'] = df['Feed'].str.replace('[^a-zA-Z0-9\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "\n",
    "# Load CSV dataset\n",
    "df = pd.read_csv('Train.csv')\n",
    "df.drop(\"ID\",axis=1,inplace=True)\n",
    "# Preprocess text data\n",
    "# Remove punctuations and special characters\n",
    "df['Feed'] = df['Feed'].str.replace('[^a-zA-Z0-9\\s]', '')\n",
    "# Convert text to lowercase\n",
    "df['Feed'] = df['Feed'].str.lower()\n",
    "# Replace NaN values with empty strings\n",
    "df['Feed'].fillna('', inplace=True)\n",
    "\n",
    "# Tokenize text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['Feed'].values)\n",
    "\n",
    "# Save tokenizer as a JSON file\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(tokenizer.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5ffbb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('modeldarijaV2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0f19386",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 250), found shape=(None, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27868\\798448624.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_padded_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_padded_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 250), found shape=(None, 2)\n"
     ]
    }
   ],
   "source": [
    "test_texts = ['This is a positive sentence.', 'This is a negative sentence.']\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_padded_sequences = pad_sequences(test_sequences)\n",
    "predictions = model.predict(test_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81496cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 250, 128)          640000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 250, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,034,754\n",
      "Trainable params: 1,034,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('modeldarijaV2.h5')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4648c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
